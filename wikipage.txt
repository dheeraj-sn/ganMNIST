Generative Adversarial Networks, or GANs, are an architecture for training generative models, such as deep convolutional neural networks for generating images.

Developing a GAN for generating images requires both a discriminator convolutional neural network model for classifying whether a given image is real or generated and a generator model that uses inverse convolutional layers to transform an input to a full two-dimensional image of pixel values.

We will develop a generative adversarial network with deep convolutional networks for generating handwritten digits using a well known dataset the MNIST. Using small and well-understood datasets means that smaller models can be developed and trained quickly, allowing the focus to be put on the model architecture and image generation process itself.

We will learn about - 
1. Defining a standalone discriminator model for learning the difference between real and fake images.
2. Defining a standalone generator model and training the composite generator and discriminator model.
3. Evaluate the performance of the GAN and use the final standalone generator model to generate new images.

We have divided the code into the following parts for easy understandability - 
1. Loading and examination of the MNIST dataset
2. Defining the discriminator model
3. Defining and using the generator model
5. The composite discriminator and generator model(GAN)
4. Evaluating GAN model performance
5. Training the composite discriminator and generator model
6. Using final trained generator model to generate images

